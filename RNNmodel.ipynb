{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e421ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle, torch, random\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c22b50aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "#def set_seed(seed = 42):\n",
    "#    random.seed(seed)\n",
    "#    np.random.seed(seed)\n",
    "#    torch.manual_seed(seed) \n",
    "#    torch.cuda.manual_seed(seed)\n",
    "\n",
    "#def seed_worker(worker_id): \n",
    "    # https://pytorch.org/docs/master/notes/randomness.html#dataloader - for reproducibility\n",
    "#    worker_seed = torch.initial_seed() % 2**32\n",
    "#    numpy.random.seed(worker_seed)\n",
    "#    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ed1da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def givemereward(original, predicted):\n",
    "    \n",
    "    '''\n",
    "      original: right decision\n",
    "      predicted: model output for the decision\n",
    "    '''\n",
    "    \n",
    "    #print('predicted before: ', predicted.size(), predicted)\n",
    "    predicted = predicted.argmax(dim=1) \n",
    "    #print('predicted after: ', predicted.size(), predicted)\n",
    "    #print('orig: ', original.size(), original)\n",
    "    \n",
    "    reward = abs(original - predicted)\n",
    "    \" 0 is succesfull, 1 is error\"\n",
    "\n",
    "    return nn.functional.one_hot(reward) # converting to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7dae5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data, dt):\n",
    "    \n",
    "    '''\n",
    "    - increases the resolution of trials from 1 step/trial to (6/dt) step/trial\n",
    "      -> 6 sec is the examined time range: - 1.5 sec before stimulus (context info only)\n",
    "                                           - the 3 sec of stimulus (context + stimulus info)\n",
    "                                           - 1.5 sec after stimulus (context info only)\n",
    "    '''\n",
    "    \n",
    "    mask_out = torch.ones(data.size())\n",
    "    mask_out[:,:,2:] = 0 # context information only - no signal yet\n",
    "    x_out = mask_out*data\n",
    "    seq_length = (4.5+1.5)/dt # 1.5 + 3 + 1.5 = 6 sec - range examined\n",
    "    block1 = int(seq_length/2) # 3 sec - duration of stimulus \n",
    "    block2 = int(seq_length/4) # 1.5 sec - before and after stim\n",
    "    block_out = torch.cat((x_out,)*block2,dim=1)\n",
    "    block_stim = torch.cat((data,)*block1,dim=1)\n",
    "    data = torch.cat((block_out,block_stim,block_out),dim=1) \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bba4eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(S, inc = False): \n",
    "    \n",
    "    class dataset(Dataset):\n",
    "        def __init__(self, S):\n",
    "            \n",
    "            '''\n",
    "               S: trials per block = how many trials are within a given sequence\n",
    "                  overall number of trials depends on S (to cover all possible combinations):\n",
    "                     - n_trials (n) = 4^S + 4^S (corresponding to the 2 different context)\n",
    "                     - n_trials (n) = 2^S + 2^S for incongruent trials only \n",
    "                     - example: S=2 -> n = 4x4 + 4x4 OR n = 2x2 + 2x2\n",
    "               inc: bool - if True: incongruent trials only \n",
    "                         - deafult False: all possible trial combinations (conr + incongr as well)\n",
    "            '''\n",
    "            \n",
    "            if inc:\n",
    "                n_comb = 2 # 2 possible combinations for each context\n",
    "                index_list = [0,1]\n",
    "            else:\n",
    "                n_comb = 4 # 4 possible combinations for each context\n",
    "                index_list = [0,1,2,3]\n",
    "            # = n_comb^S combinations \n",
    "    \n",
    "            sequences = np.zeros((n_comb**(S), S))\n",
    "            sequences[:, 0] =  np.concatenate([index_list]*n_comb**(S-1))\n",
    "            list_next = index_list\n",
    "    \n",
    "            for s in range(1,S):\n",
    "                list_next = np.repeat(list_next, n_comb)\n",
    "                sequences[:, s] = np.concatenate([list_next]*n_comb**(S-s-1))\n",
    "    \n",
    "            if inc: \n",
    "                # all possible trial combinations in one-hot encoded form:\n",
    "                variations_onehot = np.array([[[1,0,0,1]],[[0,1,1,0]]]) # the 2 incongrent trials\n",
    "                # correct decisions for both context\n",
    "                # 1 = go vs 0 = nogo\n",
    "                id_dec_aud = np.array([1,0])\n",
    "                id_dec_vis = np.array([0,1])\n",
    "            else:\n",
    "                variations_onehot = np.array([[[1,0,1,0]],[[1,0,0,1]],[[0,1,1,0]],[[0,1,0,1]]])\n",
    "                # (aud go, vis go), (aud go, vis nogo), (aud nogo, vis go), (aud nogo, vis nogo) = \n",
    "                # corresponding ideal (correct) decisions = 1, 1, 0, 0 - if context audio\n",
    "                # corresponding ideal (correct) decisions = 1, 0, 1, 0 - if context visual\n",
    "                id_dec_aud = np.array([1,1,0,0])  \n",
    "                id_dec_vis = np.array([1,0,1,0])\n",
    "    \n",
    "            data_onehot = variations_onehot[list(map(int,sequences[:,0]))]\n",
    "            d_aud_list = [id_dec_aud[list(map(int,sequences[:,0]))]]\n",
    "            d_vis_list = [id_dec_vis[list(map(int,sequences[:,0]))]]\n",
    "    \n",
    "            for s in range(1,S):\n",
    "                data_onehot = np.concatenate([data_onehot, variations_onehot[list(map(int,sequences[:,s]))]], axis = 1)\n",
    "        \n",
    "                d_aud_list.append(id_dec_aud[list(map(int,sequences[:,s]))])\n",
    "                d_vis_list.append(id_dec_vis[list(map(int,sequences[:,s]))])\n",
    "\n",
    "            data_onehot = np.concatenate([data_onehot, data_onehot]) # same pattern for the both context\n",
    "    \n",
    "            d_aud = np.vstack(d_aud_list).transpose()\n",
    "            d_vis = np.vstack(d_vis_list).transpose()\n",
    "            decision = np.concatenate([d_aud, d_vis])\n",
    "            \n",
    "            self.data_onehot = torch.tensor(data_onehot) \n",
    "            # of size: (#trials, #trials_per_block, #features=aud_go/nogo,vis_go/nogo)\n",
    "            self.decision = torch.tensor(decision) \n",
    "            # of size: (#trials, #trials_per_block)\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.decision)\n",
    "\n",
    "        def __getitem__(self, idx, type='natural'):\n",
    "            return self.data_onehot[idx], self.decision[idx]\n",
    "    \n",
    "        \n",
    "    return dataset(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f8dbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.rnn = nn.RNNCell(\n",
    "            input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, objective):\n",
    "        \n",
    "        '''\n",
    "          x: dataset from make_data() + batched with dataloader -> batched stimulus \n",
    "             - of size = (batch size, trials_per_block, 4) (4: corresponds to one-hot a/v signals)\n",
    "             - each row corresponds to a sequence (block)\n",
    "             - last trial within a sequence is used to calculate loss\n",
    "          objective: correct decision (1 = go vs 0 = nogo)\n",
    "             - of size = (batch size, trials_per_block)\n",
    "        '''\n",
    "\n",
    "        #print('x.size', x.size())\n",
    "        hx = torch.randn(x.size(0), self.hidden_dim).requires_grad_() \n",
    "        #print('hx', hx.size())\n",
    "        reward = torch.zeros(x.size(0), 2).requires_grad_() # 2 for one-hot encoded reward \n",
    "        \n",
    "        for t in range(x.size(1)): # going through trials within the sequence/block\n",
    "        \n",
    "            rnn_input = torch.zeros(1, x.size(0), self.input_dim)\n",
    "            rnn_input[0,:,0:4] = x[:,t,:] \n",
    "            rnn_input[0,:,4:6] = reward           \n",
    "            rnn_input = rnn_input.permute(1, 0, 2)\n",
    "            rnn_input = prep_data(rnn_input, 0.3)\n",
    "            out = [hx] \n",
    "            y_out = [self.fc(hx).detach().numpy()] \n",
    "        \n",
    "            for i in range(rnn_input.size(1)): # going through within trial times \n",
    "                #hx = self.rnn(rnn_input[i,:,:], hx) #- old\n",
    "                hx = self.rnn(rnn_input[:,i,:], hx) \n",
    "                out.append(hx)\n",
    "                y_out.append(self.fc(hx).detach().numpy()) \n",
    "            \n",
    "            out = torch.stack(out)\n",
    "\n",
    "            rnn_out = out[11, :, :] # 2 sec + its overwritten after every inter sequence trial\n",
    "                                    # meaning only the last inter sequence trial is used to calculate loss\n",
    "\n",
    "            rnn_out = self.fc(rnn_out) # y_hat\n",
    "            \n",
    "            reward = givemereward(objective[:,t], rnn_out) # we have to know the correct context dependent \n",
    "                                                           # decision in order to calculate reward that\n",
    "                                                           # can't be random\n",
    "        \n",
    "        return rnn_out\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f3e4044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer, log = False):\n",
    "        \n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn # criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.log = log\n",
    "        \n",
    "        self.train_loss, self.test_loss = [], []\n",
    "        self.train_acc, self.test_acc = [], []\n",
    "    \n",
    "    def train(self, train_loader, test_loader): \n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            if self.log:\n",
    "                print(f'Epoch {epoch}\\n')\n",
    "            \n",
    "            correct_train, loss_train = 0, 0\n",
    "            \n",
    "            for i,(input, objective) in enumerate(train_loader): # objective = decision\n",
    "            \n",
    "                input = input.to(device)\n",
    "                objective = objective.to(device)\n",
    "            \n",
    "                self.model.train()\n",
    "            \n",
    "                output = self.model(input, objective)\n",
    "                output = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "                # only last inter sequence trial is used to calculate loss\n",
    "                objective = torch.unsqueeze(objective[:,-1],1).to(device) \n",
    "                objective = objective.squeeze()\n",
    "                loss = self.loss_fn(output.float(), objective.long())\n",
    "                loss_train += loss\n",
    "                correct_train += (output.argmax(dim=1) == objective).sum().item()\n",
    "            \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "                if (i+1) % (len(train_loader)//3) == 0 and self.log:\n",
    "                    print (f'Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "                    \n",
    "            loss_train /= len(train_loader)\n",
    "            correct_train /= len(train_loader.dataset)\n",
    "            \n",
    "            self.train_loss.append(loss_train.detach().numpy())\n",
    "            self.train_acc.append(100*correct_train)\n",
    "        \n",
    "            correct_test, loss_test = 0, 0 # egy loss es egy acc mert 1 epoch-ra szamol\n",
    "        \n",
    "            with torch.no_grad():\n",
    "            \n",
    "                for i, (input, objective) in enumerate(test_loader):\n",
    "                    \n",
    "                    input = input.to(device)\n",
    "                    objective = objective.to(device)\n",
    "                    \n",
    "                    self.model.eval()\n",
    "                \n",
    "                    output = self.model(input, objective)\n",
    "                    \n",
    "                    objective = torch.unsqueeze(objective[:,-1],1)#.to(self.cpu)\n",
    "                    objective = objective.squeeze()\n",
    "                  #  loss_test += self.loss_fn(nn.functional.softmax(output,dim=1).float(),objective.long())\n",
    "                    loss_test += self.loss_fn(output.float(), objective.long())\n",
    "                    correct_test += (output.argmax(dim=1) == objective).sum().item()\n",
    "\n",
    "                loss_test /= len(test_loader)\n",
    "                correct_test /= len(test_loader.dataset)    \n",
    "                \n",
    "                self.test_loss.append(loss_test.detach().numpy())\n",
    "                self.test_acc.append(100*correct_test)\n",
    "            \n",
    "                if self.log:\n",
    "                    print(f\"Accuracy: {(100*correct_test):>0.1f}%, Avg loss: {loss_test:>8f}\")\n",
    "                \n",
    "    def plot_losses(self, path = ''):\n",
    "        fig, ax = plt.subplots(1,2,figsize = (13,4))\n",
    "        ax[0].plot(self.train_loss, label=\"Train loss\")\n",
    "        ax[0].plot(self.test_loss, label=\"Test loss\")\n",
    "        ax[0].legend()\n",
    "        ax[0].set_title(\"Losses\")\n",
    "        ax[0].set_xlabel(\"# epoch\")\n",
    "        \n",
    "        ax[1].plot(self.train_acc, label=\"Train accuracy\")\n",
    "        ax[1].plot(self.test_acc, label=\"Test accuracy\")\n",
    "        ax[1].legend()\n",
    "        ax[1].set_title(\"Accuracy\")\n",
    "        ax[1].set_xlabel(\"# epoch\")\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        if bool(path): \n",
    "            plt.savefig(path + '.png')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1bd5847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100 #100\n",
    "train_blocks = 100 # block = sequence - 100\n",
    "test_blocks = 10 # 10\n",
    "trials_per_block = 4 # 8\n",
    "learning_rate = 1e-4 # 1e-4\n",
    "weight_decay = 1e-4 #1e-4\n",
    "\n",
    "\n",
    "input_dim = 6 # aud, vis onehot + reward onehot\n",
    "hidden_dim = 8 # number of neurons (16)\n",
    "output_dim = 2 \n",
    "batch_size = 8 # 4\n",
    "\n",
    "train_dataset = make_data(trials_per_block, inc = False)\n",
    "test_dataset = make_data(trials_per_block, inc = False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size)\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "opt = Optimization(model = model, loss_fn = loss_fn, optimizer = optimizer, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "63c53001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulus, objective = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9fadb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 885 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opt.train(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28877601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a7906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7141c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
